# Kimi K1.5: Long Context RL 的伟大实践

感谢 kimi 团队的这篇雄文。大概在 DeepSeek 开源 R1 的同一时间，就有许多朋友向我推荐过 K1.5 的技术报告。苦于工作繁琐，一直没有空拜读。正好最近去西雅图出差，在 LAX 往返 SEA 的路上终于有时间虔诚地读完这一工作。越读起来，越有一种文人相赏，难逢知音的感觉。

本科毕业以来，确实有感受到自己在团队协作和个人能力上的长足长进。但是博士入学之后，我一直没有什么高强度投入的工作发表，未免感到焦虑。今天读完这样的雄文，心情大爽。希望自己能在余下的科研生涯中多参与这样具有开源精神的重磅工作。能让自己的名字出现在此番工作的作者名录之上，不比多发几篇 XXX 或者 XXXX 的论文强？当然，这就又带来了在大项目中，如何证明自己 credit 的问题。不过，我总归相信自己的想法仍是大有裨益的。

絮絮叨叨说了这么多，这篇文章主要复盘自己拜读 K1.5 技术报告的思索。由于是技术报告，这篇扎实的文章涵盖了从数据、训练方法到训练系统的方方面面，读完真是余音绕梁，不绝如缕。

## 